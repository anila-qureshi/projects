{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb0be2b-60aa-46f1-a002-f8f2813a9ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import api_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca16d79-da3c-4c26-befe-b63c97ceedc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repositories = [\n",
    "    \"https://github.com/huggingface/transformers\",\n",
    "    \"https://github.com/pandas-dev/pandas\",\n",
    "    \"https://github.com/EleutherAI/gpt-neo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c088d8-e518-4fcc-a85e-22b87b3c0405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/huggingface/transformers\n",
      "Error getting author for commit 43badf217d1ccfaf486e2cbb1b3567226b5e95bf: fatal: ambiguous argument '43badf217d1ccfaf486e2cbb1b3567226b5e95bf^..43badf217d1ccfaf486e2cbb1b3567226b5e95bf': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "https://github.com/pandas-dev/pandas\n",
      "Error getting author for commit 9d0080576446de475d34b0dbb58389b15cd4f529: fatal: ambiguous argument '9d0080576446de475d34b0dbb58389b15cd4f529^..9d0080576446de475d34b0dbb58389b15cd4f529': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "https://github.com/EleutherAI/gpt-neo\n",
      "Error getting author for commit 20ada4c772beb0717f06522043d0fc08a38cb527: fatal: ambiguous argument '20ada4c772beb0717f06522043d0fc08a38cb527^..20ada4c772beb0717f06522043d0fc08a38cb527': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('connor',\n",
       " '2020-07-05 10:25:41 +0000',\n",
       " 'Initial commit, working with sparse attention by bmk',\n",
       " CompletedProcess(args=['git', 'diff', '--shortstat', '20ada4c772beb0717f06522043d0fc08a38cb527^..20ada4c772beb0717f06522043d0fc08a38cb527'], returncode=128, stdout='', stderr=\"fatal: ambiguous argument '20ada4c772beb0717f06522043d0fc08a38cb527^..20ada4c772beb0717f06522043d0fc08a38cb527': unknown revision or path not in the working tree.\\nUse '--' to separate paths from revisions, like this:\\n'git <command> [<revision>...] -- [<file>...]'\\n\"))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_scraper.results(repositories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b515b91-a809-4b03-ac8d-a3f5ee887b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this was a test I initially wrote in order to see whether my script was working \n",
    "# csv_file_path = '/Users/anilaqureshi/Downloads/api_scraper.py'\n",
    "\n",
    "# try:\n",
    "#     with open(csv_file_path, 'r') as file:\n",
    "#         csv_contents = file.read()\n",
    "#     csv_contents  # Display the contents of the CSV file if available\n",
    "# except FileNotFoundError:\n",
    "#     \"The file 'commit_data.csv' does not exist or was not created.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11973b42-b9ba-46b7-a043-1f5ddc4a4943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is to see if the file exists. Earlier I could execute my python file but I didn't get the desired result. this helped me to check whether it was working\n",
    "\n",
    "# Check if the file exists\n",
    "import os\n",
    "if os.path.exists('/Users/anilaqureshi/Downloads/api_scraper.py'):\n",
    "    # If it exists, let's read and display the first few lines to understand its structure.\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        # Reading the first few lines of the CSV file\n",
    "        first_few_lines = [next(file) for _ in range(5)]\n",
    "    first_few_lines\n",
    "else:\n",
    "    \"The file 'commit_data.csv' does not exist in the current directory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2846c15e-9814-4c1b-a7fd-b2594cfd3e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 'import subprocess\\nimport csv\\nimport os\\n\\n# List of repository URLs\\nrepositories = [\\n    \"https://github.com/huggingface/transformers\",\\n    \"https://github.com/Anthropic/claude\",\\n    \"https://github.com/EleutherAI/gpt-neo\",\\n]\\ndef results(repositories):\\n    # Create a CSV file to store the commit data\\n    csv_file = \"commit_data.csv\"\\n\\n    # Create a CSV writer\\n    with open(csv_file, mode=\"w\", newline=\"\") as file:\\n        csv_writer = csv.writer(file)\\n\\n        # Write header row\\n        csv_writer.writerow([\"Repository\", \"Commit Hash\", \"Author\", \"Date and Time\", \"Commit Message\", \"Insertions\", \"Deletions\"])\\n\\n        # Loop through each repository\\n        for repo_url in repositories:\\n            print(repo_url) # print for my own sanity\\n            # Extract repository name from the URL\\n            repo_name = repo_url.split(\"/\")[-1].replace(\".git\", \"\")\\n\\n            # Specify the full path to the repository directory\\n            repo_directory = os.path.join(os.getcwd(), repo_name)\\n\\n            # Clone the repository if it doesn\\'t exist\\n            if not os.path.exists(repo_directory):\\n                subprocess.run([\"git\", \"clone\", repo_url], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n\\n            # Change to the repository directory\\n            os.chdir(repo_directory)\\n\\n            # Fetch the latest changes\\n            subprocess.run([\"git\", \"fetch\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n\\n            # Get the list of all commit hashes from newest to oldest\\n            commit_hashes = subprocess.run([\"git\", \"log\", \"--format=\\'%H\\'\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\\n            # Get the list of all commit hashes (newest first by default)\\n\\n            commit_hashes = commit_hashes.stdout.strip().split(\"\\\\n\")\\n\\n            # Loop through each commit hash\\n            for hash in commit_hashes:\\n                hash = hash.strip(\"\\'\")\\n                # Get commit author\\n                author_results = subprocess.run([\"git\", \"log\", \"-n\", \"1\", \"--pretty=format:%an\", hash], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\\n                if author_results.stderr:\\n                    print(f\"Error getting author for commit {hash}: {author_results.stderr}\")\\n                    continue\\n                author = author_results.stdout.strip()\\n                # print(author,len(author))  --commented out but can be used for additional testing\\n                \\n                \\n                # Get commit date and time\\n                datetime = subprocess.run([\"git\", \"log\", \"-n\", \"1\", \"--pretty=format:%ad\", \"--date=iso\", hash], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout.strip()\\n                # print(datetime, len(datetime)) --commented out but can be used for additional testing\\n                \\n                \\n                # Get commit message\\n                message = subprocess.run([\"git\", \"log\", \"-n\", \"1\", \"--pretty=format:%s\", hash], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\\n                # print(message, len(message))  --commented out but can be used for additional testing\\n                if message.stderr:\\n                    print(f\"Error getting message for commit {hash}: {message.stderr}\")\\n                    continue\\n                message = message.stdout.strip()\\n                \\n                # Get the number of insertions and deletions\\n                stats = subprocess.run([\"git\", \"diff\", \"--shortstat\", f\"{hash}^..{hash}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\\n                if stats.stderr:\\n                    print(f\"Error getting author for commit {hash}: {stats.stderr}\")\\n                    continue\\n                stats = stats.stdout.strip()\\n                \\n                # Split the insertions and deletions from the statistics\\n                stats_parts = stats.split(\",\")\\n                # print(len)  --commented out but can be used for additional testing\\n                insertions = stats_parts[0].strip() if len(stats_parts) > 0 else \"0\"\\n                deletions = stats_parts[1].strip() if len(stats_parts) > 1 else \"0\"\\n\\n                # Write commit data to the CSV file\\n                csv_writer.writerow([repo_name, hash, author, datetime, message, insertions, deletions])\\n\\n            # Return to the parent directory\\n            os.chdir(\"..\")\\n    return author, datetime, message, stats')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempting a different approach to check for the file and read its contents if it exists\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = '/Users/anilaqureshi/Downloads/api_scraper.py'\n",
    "\n",
    "# Check if the file exists\n",
    "file_exists = os.path.isfile(csv_file_path)\n",
    "\n",
    "# Initialize an empty variable to hold the contents\n",
    "csv_contents = None\n",
    "\n",
    "# If the file exists, read its contents\n",
    "if file_exists:\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        csv_contents = file.read()\n",
    "\n",
    "file_exists, csv_contents  # Display whether the file exists and its contents if it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462dbc54-adc1-46bd-88fd-f4a80bc3d995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the directory for the CSV file directly\n",
    "csv_file_name = \"commit_data.csv\"\n",
    "csv_directory = \"/Users/anilaqureshi/Downloads/api_scraper.py\"\n",
    "csv_file_path = os.path.join(csv_directory, csv_file_name)\n",
    "\n",
    "# Checking if the file exists\n",
    "csv_file_exists = os.path.isfile(csv_file_path)\n",
    "\n",
    "# Reading the contents of the CSV file if it exists\n",
    "csv_contents = []\n",
    "if csv_file_exists:\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        csv_contents = list(csv_reader)  # Read all the contents in a list\n",
    "\n",
    "csv_file_exists, csv_contents[:5]  # Check if the file exists and preview first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b035be47-0320-40ca-8765-bda489c55644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# def scrape_repository_data(repositories):\n",
    "#     csv_file = os.path.abspath(\"commit_data.csv\")\n",
    "#     with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "#         csv_writer = csv.writer(file)\n",
    "#         csv_writer.writerow([\"Repository\", \"Commit Hash\", \"Author\", \"Date and Time\", \"Commit Message\", \"Insertions\", \"Deletions\"])\n",
    "#         for repo_url in repositories:\n",
    "#             repo_name = repo_url.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "#             repo_directory = os.path.join(os.getcwd(), repo_name)\n",
    "#             if not os.path.exists(repo_directory):\n",
    "#                 clone_result = subprocess.run([\"git\", \"clone\", repo_url], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=os.getcwd())\n",
    "#                 if clone_result.returncode != 0:\n",
    "#                     print(f\"Error cloning {repo_url}: {clone_result.stderr}\")\n",
    "#                     continue\n",
    "#             fetch_result = subprocess.run([\"git\", \"fetch\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=repo_directory)\n",
    "#             if fetch_result.returncode != 0:\n",
    "#                 print(f\"Error fetching {repo_url}: {fetch_result.stderr}\")\n",
    "#                 continue\n",
    "#             commit_hashes_result = subprocess.run([\"git\", \"log\", \"--format='%H'\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=repo_directory)\n",
    "#             if commit_hashes_result.returncode != 0:\n",
    "#                 print(f\"Error getting commits for {repo_url}: {commit_hashes_result.stderr}\")\n",
    "#                 continue\n",
    "#             commit_hashes = commit_hashes_result.stdout.strip().split(\"\\n\")\n",
    "#             for hash in commit_hashes:\n",
    "#                 hash = hash.strip(\"'\")\n",
    "#                 # Get commit details\n",
    "#                 commit_details_result = subprocess.run([\"git\", \"show\", \"--no-patch\", \"--format=%an|%ad|%s\", \"--date=iso\", hash], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=repo_directory)\n",
    "#                 if commit_details_result.returncode != 0:  # Check if show was successful\n",
    "#                     print(f\"Error showing commit {hash}: {commit_details_result.stderr}\")\n",
    "#                     continue\n",
    "#                 try:\n",
    "#                     author, datetime, message = commit_details_result.stdout.strip().split(\"|\", 2)\n",
    "#                 except ValueError as e:\n",
    "#                     print(f\"Error parsing commit details for {hash}: {e}\")\n",
    "#                 continue\n",
    "#             # for hash in commit_hashes:\n",
    "#             #     hash = hash.strip(\"'\")\n",
    "#             #     commit_details_result = subprocess.run([\"git\", \"show\", \"--no-patch\", \"--format=%an|%ad|%s\", \"--date=iso\", hash], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=repo_directory)\n",
    "#             #     if commit_details_result.returncode != 0:\n",
    "#             #         print(f\"Error showing commit {hash}: {commit_details_result.stderr}\")\n",
    "#             #         continue\n",
    "#             #     author, datetime, message = commit_details_result.stdout.strip().split(\"|\")\n",
    "#             #     stats_result = subprocess.run([\"git\", \"diff\", \"--shortstat\", f\"{hash}^..{hash}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=repo_directory)\n",
    "#             #     if stats_result.returncode != 0:\n",
    "#             #         print(f\"Error diffing commit {hash}: {stats_result.stderr}\")\n",
    "#             #         continue\n",
    "#                 stats = stats_result.stdout.strip()\n",
    "#                 insertions = \"0 insertions\"\n",
    "#                 deletions = \"0 deletions\"\n",
    "#                 if stats:\n",
    "#                     stats_parts = stats.split(\", \")\n",
    "#                     for stat in stats_parts:\n",
    "#                         if 'insertion' in stat:\n",
    "#                             insertions = stat\n",
    "#                         elif 'deletion' in stat:\n",
    "#                             deletions = stat\n",
    "#                 csv_writer.writerow([repo_name, hash, author, datetime, message, insertions, deletions])\n",
    "#     return \"Data scraping completed successfully.\"\n",
    "\n",
    "# # List of repository URLs\n",
    "# repositories = [\n",
    "#     \"https://github.com/huggingface/transformers\",\n",
    "#     \"https://github.com/Anthropic/claude\",\n",
    "#     \"https://github.com/EleutherAI/gpt-neo\",\n",
    "# ]\n",
    "\n",
    "# # Execute the function\n",
    "# result_message = scrape_repository_data(repositories)\n",
    "# print(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e681eb-1300-48ff-8a57-a2ceadf4b519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'csv', 'os', 'repositories', 'results', 'subprocess']\n"
     ]
    }
   ],
   "source": [
    "#checking to see if repositories exists \n",
    "print(dir(api_scraper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f311428-7205-4e47-9369-5db70f18a934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
